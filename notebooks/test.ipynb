{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing d:\\aiplan4grid\\dist\\plan4grid-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: Grid2Op in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (1.9.5)\n",
      "Requirement already satisfied: numba==0.56.4 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (0.56.4)\n",
      "Requirement already satisfied: numpy==1.23.5 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (1.23.5)\n",
      "Requirement already satisfied: pandapower==2.13.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (2.13.1)\n",
      "Requirement already satisfied: unified-planning==1.0.0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: up-enhsp==0.0.15 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (0.0.15)\n",
      "Requirement already satisfied: matplotlib in d:\\aiplan4grid\\.venv\\lib\\site-packages (from plan4grid==0.0.1) (3.8.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from numba==0.56.4->plan4grid==0.0.1) (0.39.1)\n",
      "Requirement already satisfied: setuptools in d:\\aiplan4grid\\.venv\\lib\\site-packages (from numba==0.56.4->plan4grid==0.0.1) (68.2.0)\n",
      "Requirement already satisfied: pandas>=1.0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: networkx>=2.5 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (3.1)\n",
      "Requirement already satisfied: scipy in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (1.11.2)\n",
      "Requirement already satisfied: packaging in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (23.1)\n",
      "Requirement already satisfied: tqdm in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (4.66.1)\n",
      "Requirement already satisfied: deepdiff in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandapower==2.13.1->plan4grid==0.0.1) (6.5.0)\n",
      "Requirement already satisfied: pyparsing in d:\\aiplan4grid\\.venv\\lib\\site-packages (from unified-planning==1.0.0->plan4grid==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from Grid2Op->plan4grid==0.0.1) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from matplotlib->plan4grid==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandas>=1.0->pandapower==2.13.1->plan4grid==0.0.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from pandas>=1.0->pandapower==2.13.1->plan4grid==0.0.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->plan4grid==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from requests>=2.23.0->Grid2Op->plan4grid==0.0.1) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from requests>=2.23.0->Grid2Op->plan4grid==0.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from requests>=2.23.0->Grid2Op->plan4grid==0.0.1) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from requests>=2.23.0->Grid2Op->plan4grid==0.0.1) (2023.7.22)\n",
      "Requirement already satisfied: colorama in d:\\aiplan4grid\\.venv\\lib\\site-packages (from tqdm->pandapower==2.13.1->plan4grid==0.0.1) (0.4.6)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in d:\\aiplan4grid\\.venv\\lib\\site-packages (from deepdiff->pandapower==2.13.1->plan4grid==0.0.1) (4.1.0)\n",
      "plan4grid is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../dist/\")\n",
    "%pip install plan4grid-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plan4grid.AIPlan4GridAgent import AIPlan4GridAgent\n",
    "from grid2op.Backend import PandaPowerBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"educ_case14_storage\"\n",
    "tactical_horizon = 1\n",
    "strategic_horizon = 288\n",
    "solver = \"enhsp\"\n",
    "scenario_id = 2\n",
    "time_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIPlan4Grid\\.venv\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:420: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "from grid2op.Chronics import FromHandlers\n",
    "from grid2op.Chronics.handlers import (\n",
    "    CSVHandler,\n",
    "    DoNothingHandler,\n",
    "    PerfectForecastHandler,\n",
    ")\n",
    "env = grid2op.make(\n",
    "    dataset=env_name,\n",
    "    data_feeding_kwargs={\n",
    "        \"gridvalueClass\": FromHandlers,\n",
    "        \"gen_p_handler\": CSVHandler(\"prod_p\"),\n",
    "        \"load_p_handler\": CSVHandler(\"load_p\"),\n",
    "        \"gen_v_handler\": DoNothingHandler(\"prod_v\"),\n",
    "        \"load_q_handler\": CSVHandler(\"load_q\"),\n",
    "        \"h_forecast\": [h * time_step for h in range(1, tactical_horizon + 1)],\n",
    "        \"gen_p_for_handler\": PerfectForecastHandler(\"prod_p_forecasted\"),\n",
    "        \"load_p_for_handler\": PerfectForecastHandler(\"load_p_forecasted\"),\n",
    "        \"load_q_for_handler\": PerfectForecastHandler(\"load_q_forecasted\"),\n",
    "    },\n",
    "    test=True,\n",
    "    backend=PandaPowerBackend(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AIPlan4GridAgent(\n",
    "    env=env,\n",
    "    scenario_id=scenario_id,\n",
    "    tactical_horizon=tactical_horizon,\n",
    "    solver=solver,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Episode 0:\n",
      "\tReward: 15.657416343688965\n",
      "\n",
      "* Episode 1:\n",
      "\tReward: 15.738021850585938\n",
      "\n",
      "* Episode 2:\n",
      "\tReward: 15.651633262634277\n",
      "\n",
      "* Episode 3:\n",
      "\tReward: 15.674113273620605\n",
      "\n",
      "* Episode 4:\n",
      "\tReward: 15.671775817871094\n",
      "\n",
      "* Episode 5:\n",
      "\tReward: 15.667729377746582\n",
      "\n",
      "* Episode 6:\n",
      "\tReward: 15.737521171569824\n",
      "\n",
      "* Episode 7:\n",
      "\tReward: 15.826396942138672\n",
      "\n",
      "* Episode 8:\n",
      "\tReward: 15.865304946899414\n",
      "\n",
      "* Episode 9:\n",
      "\tReward: 15.943458557128906\n",
      "\n",
      "* Episode 10:\n",
      "\tReward: 15.993526458740234\n",
      "\n",
      "* Episode 11:\n",
      "\tReward: 15.968756675720215\n",
      "\n",
      "* Episode 12:\n",
      "\tReward: 16.120397567749023\n",
      "\n",
      "* Episode 13:\n",
      "\tReward: 16.04901123046875\n",
      "\n",
      "* Episode 14:\n",
      "\tReward: 16.098432540893555\n",
      "\n",
      "* Episode 15:\n",
      "\tReward: 16.13287925720215\n",
      "\n",
      "* Episode 16:\n",
      "\tReward: 16.12594985961914\n",
      "\n",
      "* Episode 17:\n",
      "\tReward: 16.122817993164062\n",
      "\n",
      "* Episode 18:\n",
      "\tReward: 16.05257797241211\n",
      "\n",
      "* Episode 19:\n",
      "\tReward: 16.005142211914062\n",
      "\n",
      "* Episode 20:\n",
      "\tReward: 16.076345443725586\n",
      "\n",
      "* Episode 21:\n",
      "\tReward: 16.093393325805664\n",
      "\n",
      "* Episode 22:\n",
      "\tReward: 16.062467575073242\n",
      "\n",
      "* Episode 23:\n",
      "\tReward: 16.15550994873047\n",
      "\n",
      "* Episode 24:\n",
      "\tReward: 16.159584045410156\n",
      "\n",
      "* Episode 25:\n",
      "\tReward: 16.07445526123047\n",
      "\n",
      "* Episode 26:\n",
      "\tReward: 16.100982666015625\n",
      "\n",
      "* Episode 27:\n",
      "\tReward: 16.1102294921875\n",
      "\n",
      "* Episode 28:\n",
      "\tReward: 16.144824981689453\n",
      "\n",
      "* Episode 29:\n",
      "\tReward: 16.067777633666992\n",
      "\n",
      "* Episode 30:\n",
      "\tReward: 16.131738662719727\n",
      "\n",
      "* Episode 31:\n",
      "\tReward: 16.18388557434082\n",
      "\n",
      "* Episode 32:\n",
      "\tReward: 16.096233367919922\n",
      "\n",
      "* Episode 33:\n",
      "\tReward: 16.2322998046875\n",
      "\n",
      "* Episode 34:\n",
      "\tReward: 16.274625778198242\n",
      "\n",
      "* Episode 35:\n",
      "\tReward: 16.301773071289062\n",
      "\n",
      "* Episode 36:\n",
      "\tReward: 16.388856887817383\n",
      "\n",
      "* Episode 37:\n",
      "\tReward: 16.408912658691406\n",
      "\n",
      "* Episode 38:\n",
      "\tReward: 16.433412551879883\n",
      "\n",
      "* Episode 39:\n",
      "\tReward: 16.46775245666504\n",
      "\n",
      "* Episode 40:\n",
      "\tReward: 16.491073608398438\n",
      "\n",
      "* Episode 41:\n",
      "\tReward: 16.535036087036133\n",
      "\n",
      "* Episode 42:\n",
      "\tReward: 16.560386657714844\n",
      "\n",
      "* Episode 43:\n",
      "\tReward: 16.576343536376953\n",
      "\n",
      "* Episode 44:\n",
      "\tReward: 16.60911750793457\n",
      "\n",
      "* Episode 45:\n",
      "\tReward: 16.654951095581055\n",
      "\n",
      "* Episode 46:\n",
      "\tReward: 16.62639045715332\n",
      "\n",
      "* Episode 47:\n",
      "\tReward: 16.641347885131836\n",
      "\n",
      "* Episode 48:\n",
      "\tReward: 16.711490631103516\n",
      "\n",
      "* Episode 49:\n",
      "\tReward: 16.715879440307617\n",
      "\n",
      "* Episode 50:\n",
      "\tReward: 16.71088409423828\n",
      "\n",
      "* Episode 51:\n",
      "\tReward: 16.694751739501953\n",
      "\n",
      "* Episode 52:\n",
      "\tReward: 16.693952560424805\n",
      "\n",
      "* Episode 53:\n",
      "\tReward: 16.72692108154297\n",
      "\n",
      "* Episode 54:\n",
      "\tReward: 16.722728729248047\n",
      "\n",
      "* Episode 55:\n",
      "\tReward: 16.70269775390625\n",
      "\n",
      "* Episode 56:\n",
      "\tReward: 16.75369644165039\n",
      "\n",
      "* Episode 57:\n",
      "\tReward: 16.732938766479492\n",
      "\n",
      "* Episode 58:\n",
      "\tReward: 16.776004791259766\n",
      "\n",
      "* Episode 59:\n",
      "\tReward: 16.73729133605957\n",
      "\n",
      "* Episode 60:\n",
      "\tReward: 16.729394912719727\n",
      "\n",
      "* Episode 61:\n",
      "\tReward: 16.65964698791504\n",
      "\n",
      "* Episode 62:\n",
      "\tReward: 16.672550201416016\n",
      "\n",
      "* Episode 63:\n",
      "\tReward: 16.626140594482422\n",
      "\n",
      "* Episode 64:\n",
      "\tReward: 16.584671020507812\n",
      "\n",
      "* Episode 65:\n",
      "\tReward: 16.53089141845703\n",
      "\n",
      "* Episode 66:\n",
      "\tReward: 16.49225616455078\n",
      "\n",
      "* Episode 67:\n",
      "\tReward: 16.47061538696289\n",
      "\n",
      "* Episode 68:\n",
      "\tReward: 16.424924850463867\n",
      "\n",
      "* Episode 69:\n",
      "\tReward: 16.357271194458008\n",
      "\n",
      "* Episode 70:\n",
      "\tReward: 16.316713333129883\n",
      "\n",
      "* Episode 71:\n",
      "\tReward: 16.312978744506836\n",
      "\n",
      "* Episode 72:\n",
      "\tReward: 16.237234115600586\n",
      "\n",
      "* Episode 73:\n",
      "\tReward: 16.201255798339844\n",
      "\n",
      "* Episode 74:\n",
      "\tReward: 16.16727066040039\n",
      "\n",
      "* Episode 75:\n",
      "\tReward: 16.086721420288086\n",
      "\n",
      "* Episode 76:\n",
      "\tReward: 15.929356575012207\n",
      "\n",
      "* Episode 77:\n",
      "\tReward: 15.904276847839355\n",
      "\n",
      "* Episode 78:\n",
      "\tReward: 15.755817413330078\n",
      "\n",
      "* Episode 79:\n",
      "\tReward: 15.709061622619629\n",
      "\n",
      "* Episode 80:\n",
      "\tReward: 15.609349250793457\n",
      "\n",
      "* Episode 81:\n",
      "\tReward: 15.545133590698242\n",
      "\n",
      "* Episode 82:\n",
      "\tReward: 15.4295072555542\n",
      "\n",
      "* Episode 83:\n",
      "\tReward: 15.352677345275879\n",
      "\n",
      "* Episode 84:\n",
      "\tReward: 15.332077026367188\n",
      "\n",
      "* Episode 85:\n",
      "\tReward: 15.286161422729492\n",
      "\n",
      "* Episode 86:\n",
      "\tReward: 15.154796600341797\n",
      "\n",
      "* Episode 87:\n",
      "\tReward: 15.196885108947754\n",
      "\n",
      "* Episode 88:\n",
      "\tReward: 15.081840515136719\n",
      "\n",
      "* Episode 89:\n",
      "\tReward: 14.970931053161621\n",
      "\n",
      "* Episode 90:\n",
      "\tReward: 14.937687873840332\n",
      "\n",
      "* Episode 91:\n",
      "\tReward: 14.859926223754883\n",
      "\n",
      "* Episode 92:\n",
      "\tReward: 14.796640396118164\n",
      "\n",
      "* Episode 93:\n",
      "\tReward: 14.899535179138184\n",
      "\n",
      "* Episode 94:\n",
      "\tReward: 14.847476959228516\n",
      "\n",
      "* Episode 95:\n",
      "\tReward: 14.810225486755371\n",
      "\n",
      "* Episode 96:\n",
      "\tReward: 14.81859016418457\n",
      "\n",
      "* Episode 97:\n",
      "\tReward: 14.87164306640625\n",
      "\n",
      "* Episode 98:\n",
      "\tReward: 14.959569931030273\n",
      "\n",
      "* Episode 99:\n",
      "\tReward: 14.938971519470215\n",
      "\n",
      "* Episode 100:\n",
      "\tReward: 14.935436248779297\n",
      "\n",
      "* Episode 101:\n",
      "\tReward: 14.985674858093262\n",
      "\n",
      "* Episode 102:\n",
      "\tReward: 14.998503684997559\n",
      "\n",
      "* Episode 103:\n",
      "\tReward: 15.029620170593262\n",
      "\n",
      "* Episode 104:\n",
      "\tReward: 15.153572082519531\n",
      "\n",
      "* Episode 105:\n",
      "\tReward: 15.166523933410645\n",
      "\n",
      "* Episode 106:\n",
      "\tReward: 15.080550193786621\n",
      "\n",
      "* Episode 107:\n",
      "\tReward: 14.959640502929688\n",
      "\n",
      "* Episode 108:\n",
      "\tReward: 14.977134704589844\n",
      "\n",
      "* Episode 109:\n",
      "\tReward: 15.05072021484375\n",
      "\n",
      "* Episode 110:\n",
      "\tReward: 15.012499809265137\n",
      "\n",
      "* Episode 111:\n",
      "\tReward: 14.97999382019043\n",
      "\n",
      "* Episode 112:\n",
      "\tReward: 15.0551118850708\n",
      "\n",
      "* Episode 113:\n",
      "\tReward: 15.098956108093262\n",
      "\n",
      "* Episode 114:\n",
      "\tReward: 15.1782865524292\n",
      "\n",
      "* Episode 115:\n",
      "\tReward: 15.244612693786621\n",
      "\n",
      "* Episode 116:\n",
      "\tReward: 15.28334903717041\n",
      "\n",
      "* Episode 117:\n",
      "\tReward: 15.347602844238281\n",
      "\n",
      "* Episode 118:\n",
      "\tReward: 15.391674041748047\n",
      "\n",
      "* Episode 119:\n",
      "\tReward: 15.368318557739258\n",
      "\n",
      "* Episode 120:\n",
      "\tReward: 15.409517288208008\n",
      "\n",
      "* Episode 121:\n",
      "\tReward: 15.428154945373535\n",
      "\n",
      "* Episode 122:\n",
      "\tReward: 15.361299514770508\n",
      "\n",
      "* Episode 123:\n",
      "\tReward: 15.522469520568848\n",
      "\n",
      "* Episode 124:\n",
      "\tReward: 15.56653118133545\n",
      "\n",
      "* Episode 125:\n",
      "\tReward: 15.567546844482422\n",
      "\n",
      "* Episode 126:\n",
      "\tReward: 15.557113647460938\n",
      "\n",
      "* Episode 127:\n",
      "\tReward: 15.548781394958496\n",
      "\n",
      "* Episode 128:\n",
      "\tReward: 15.525397300720215\n",
      "\n",
      "* Episode 129:\n",
      "\tReward: 15.47565746307373\n",
      "\n",
      "* Episode 130:\n",
      "\tReward: 15.417967796325684\n",
      "\n",
      "* Episode 131:\n",
      "\tReward: 15.455936431884766\n",
      "\n",
      "* Episode 132:\n",
      "\tReward: 15.42267894744873\n",
      "\n",
      "* Episode 133:\n",
      "\tReward: 15.350711822509766\n",
      "\n",
      "* Episode 134:\n",
      "\tReward: 15.351887702941895\n",
      "\n",
      "* Episode 135:\n",
      "\tReward: 15.534765243530273\n",
      "\n",
      "* Episode 136:\n",
      "\tReward: 15.533355712890625\n",
      "\n",
      "* Episode 137:\n",
      "\tReward: 15.557672500610352\n",
      "\n",
      "* Episode 138:\n",
      "\tReward: 15.521259307861328\n",
      "\n",
      "* Episode 139:\n",
      "\tReward: 15.557265281677246\n",
      "\n",
      "* Episode 140:\n",
      "\tReward: 15.451910972595215\n",
      "\n",
      "* Episode 141:\n",
      "\tReward: 15.363945007324219\n",
      "\n",
      "* Episode 142:\n",
      "\tReward: 15.276525497436523\n",
      "\n",
      "* Episode 143:\n",
      "\tReward: 15.182929992675781\n",
      "\n",
      "* Episode 144:\n",
      "\tReward: 15.155037879943848\n",
      "\n",
      "* Episode 145:\n",
      "\tReward: 15.109138488769531\n",
      "\n",
      "* Episode 146:\n",
      "\tReward: 15.151963233947754\n",
      "\n",
      "* Episode 147:\n",
      "\tReward: 15.172904968261719\n",
      "\n",
      "* Episode 148:\n",
      "\tReward: 15.251933097839355\n",
      "\n",
      "* Episode 149:\n",
      "\tReward: 15.291138648986816\n",
      "\n",
      "* Episode 150:\n",
      "\tReward: 15.325430870056152\n",
      "\n",
      "* Episode 151:\n",
      "\tReward: 15.275233268737793\n",
      "\n",
      "* Episode 152:\n",
      "\tReward: 15.296525001525879\n",
      "\n",
      "* Episode 153:\n",
      "\tReward: 15.227115631103516\n",
      "\n",
      "* Episode 154:\n",
      "\tReward: 15.217748641967773\n",
      "\n",
      "* Episode 155:\n",
      "\tReward: 15.213644027709961\n",
      "\n",
      "* Episode 156:\n",
      "\tReward: 15.244272232055664\n",
      "\n",
      "* Episode 157:\n",
      "\tReward: 15.220471382141113\n",
      "\n",
      "* Episode 158:\n",
      "\tReward: 15.130549430847168\n",
      "\n",
      "* Episode 159:\n",
      "\tReward: 15.106267929077148\n",
      "\n",
      "* Episode 160:\n",
      "\tReward: 15.044058799743652\n",
      "\n",
      "* Episode 161:\n",
      "\tReward: 15.044548988342285\n",
      "\n",
      "* Episode 162:\n",
      "\tReward: 15.14400577545166\n",
      "\n",
      "* Episode 163:\n",
      "\tReward: 15.150335311889648\n",
      "\n",
      "* Episode 164:\n",
      "\tReward: 15.12683391571045\n",
      "\n",
      "* Episode 165:\n",
      "\tReward: 15.098637580871582\n",
      "\n",
      "* Episode 166:\n",
      "\tReward: 15.027848243713379\n",
      "\n",
      "* Episode 167:\n",
      "\tReward: 15.037532806396484\n",
      "\n",
      "* Episode 168:\n",
      "\tReward: 15.012133598327637\n",
      "\n",
      "* Episode 169:\n",
      "\tReward: 15.085399627685547\n",
      "\n",
      "* Episode 170:\n",
      "\tReward: 15.036738395690918\n",
      "\n",
      "* Episode 171:\n",
      "\tReward: 15.159897804260254\n",
      "\n",
      "* Episode 172:\n",
      "\tReward: 15.089580535888672\n",
      "\n",
      "* Episode 173:\n",
      "\tReward: 14.96922779083252\n",
      "\n",
      "* Episode 174:\n",
      "\tReward: 14.928256034851074\n",
      "\n",
      "* Episode 175:\n",
      "\tReward: 14.773645401000977\n",
      "\n",
      "* Episode 176:\n",
      "\tReward: 14.763520240783691\n",
      "\n",
      "* Episode 177:\n",
      "\tReward: 14.790351867675781\n",
      "\n",
      "* Episode 178:\n",
      "\tReward: 14.790271759033203\n",
      "\n",
      "* Episode 179:\n",
      "\tReward: 14.8816556930542\n",
      "\n",
      "* Episode 180:\n",
      "\tReward: 14.88996696472168\n",
      "\n",
      "* Episode 181:\n",
      "\tReward: 14.840020179748535\n",
      "\n",
      "* Episode 182:\n",
      "\tReward: 14.910510063171387\n",
      "\n",
      "* Episode 183:\n",
      "\tReward: 14.8080472946167\n",
      "\n",
      "* Episode 184:\n",
      "\tReward: 14.86479663848877\n",
      "\n",
      "* Episode 185:\n",
      "\tReward: 14.843207359313965\n",
      "\n",
      "* Episode 186:\n",
      "\tReward: 14.835441589355469\n",
      "\n",
      "* Episode 187:\n",
      "\tReward: 14.783300399780273\n",
      "\n",
      "* Episode 188:\n",
      "\tReward: 14.749673843383789\n",
      "\n",
      "* Episode 189:\n",
      "\tReward: 14.669260025024414\n",
      "\n",
      "* Episode 190:\n",
      "\tReward: 14.551255226135254\n",
      "\n",
      "* Episode 191:\n",
      "\tReward: 14.563426971435547\n",
      "\n",
      "* Episode 192:\n",
      "\tReward: 14.503695487976074\n",
      "\n",
      "* Episode 193:\n",
      "\tReward: 14.506484031677246\n",
      "\n",
      "* Episode 194:\n",
      "\tReward: 14.512158393859863\n",
      "\n",
      "* Episode 195:\n",
      "\tReward: 14.503663063049316\n",
      "\n",
      "* Episode 196:\n",
      "\tReward: 14.441047668457031\n",
      "\n",
      "* Episode 197:\n",
      "\tReward: 14.53663444519043\n",
      "\n",
      "* Episode 198:\n",
      "\tReward: 14.482702255249023\n",
      "\n",
      "* Episode 199:\n",
      "\tReward: 14.523670196533203\n",
      "\n",
      "* Episode 200:\n",
      "\tReward: 14.535183906555176\n",
      "\n",
      "* Episode 201:\n",
      "\tReward: 14.513731002807617\n",
      "\n",
      "* Episode 202:\n",
      "\tReward: 14.556962013244629\n",
      "\n",
      "* Episode 203:\n",
      "\tReward: 14.511822700500488\n",
      "\n",
      "* Episode 204:\n",
      "\tReward: 14.547334671020508\n",
      "\n",
      "* Episode 205:\n",
      "\tReward: 14.4642333984375\n",
      "\n",
      "* Episode 206:\n",
      "\tReward: 14.463772773742676\n",
      "\n",
      "* Episode 207:\n",
      "\tReward: 14.529300689697266\n",
      "\n",
      "* Episode 208:\n",
      "\tReward: 14.515501022338867\n",
      "\n",
      "* Episode 209:\n",
      "\tReward: 14.506092071533203\n",
      "\n",
      "* Episode 210:\n",
      "\tReward: 14.526677131652832\n",
      "\n",
      "* Episode 211:\n",
      "\tReward: 14.458513259887695\n",
      "\n",
      "* Episode 212:\n",
      "\tReward: 14.498270034790039\n",
      "\n",
      "* Episode 213:\n",
      "\tReward: 14.427270889282227\n",
      "\n",
      "* Episode 214:\n",
      "\tReward: 14.334753036499023\n",
      "\n",
      "* Episode 215:\n",
      "\tReward: 14.26209545135498\n",
      "\n",
      "* Episode 216:\n",
      "\tReward: 14.179110527038574\n",
      "\n",
      "* Episode 217:\n",
      "\tReward: 14.138460159301758\n",
      "\n",
      "* Episode 218:\n",
      "\tReward: 14.151750564575195\n",
      "\n",
      "* Episode 219:\n",
      "\tReward: 14.042107582092285\n",
      "\n",
      "* Episode 220:\n",
      "\tReward: 13.997300148010254\n",
      "\n",
      "* Episode 221:\n",
      "\tCongestion detected in the future!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\AIPlan4Grid\\notebooks\\test.ipynb Cellule 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIPlan4Grid/notebooks/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(strategic_horizon \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m tactical_horizon):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIPlan4Grid/notebooks/test.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m* Episode \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AIPlan4Grid/notebooks/test.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     obs, reward, done, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mprogress(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIPlan4Grid/notebooks/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mReward: \u001b[39m\u001b[39m{\u001b[39;00mreward\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIPlan4Grid/notebooks/test.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cumulative_reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "File \u001b[1;32md:\\AIPlan4Grid\\.venv\\lib\\site-packages\\plan4grid\\AIPlan4GridAgent.py:406\u001b[0m, in \u001b[0;36mAIPlan4GridAgent.progress\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m    404\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m    405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_states()\n\u001b[1;32m--> 406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_congestions() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_topology():\n\u001b[0;32m    407\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_UP_actions(step)\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\AIPlan4Grid\\.venv\\lib\\site-packages\\plan4grid\\AIPlan4GridAgent.py:251\u001b[0m, in \u001b[0;36mAIPlan4GridAgent.check_congestions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m         max_flow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutable_properties[cfg\u001b[39m.\u001b[39mTRANSMISSION_LINES][line][\n\u001b[0;32m    248\u001b[0m             cfg\u001b[39m.\u001b[39mMAX_FLOW\n\u001b[0;32m    249\u001b[0m         ]\n\u001b[0;32m    250\u001b[0m         flow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforecasted_states[cfg\u001b[39m.\u001b[39mFLOWS][line]\n\u001b[1;32m--> 251\u001b[0m         _print_congested_line(line, flow, max_flow)\n\u001b[0;32m    252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\AIPlan4Grid\\.venv\\lib\\site-packages\\plan4grid\\AIPlan4GridAgent.py:226\u001b[0m, in \u001b[0;36mAIPlan4GridAgent.check_congestions.<locals>._print_congested_line\u001b[1;34m(line, flow, max_flow)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_print_congested_line\u001b[39m(line, flow, max_flow):\n\u001b[0;32m    225\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mLine \u001b[39m\u001b[39m{\u001b[39;00mline\u001b[39m}\u001b[39;00m\u001b[39m is congested with a flow of \u001b[39m\u001b[39m{\u001b[39;00mflow\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m MW,\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut have a maximum/minimum flow of +/- \u001b[39m\u001b[39m{\u001b[39;00mmax_flow\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m MW\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    228\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "cumulative_reward = 0\n",
    "for i in range(strategic_horizon // tactical_horizon):\n",
    "    print(f\"\\n* Episode {i}:\")\n",
    "    obs, reward, done, *_ = agent.progress(i)\n",
    "    print(f\"\\tReward: {reward}\")\n",
    "    cumulative_reward += reward\n",
    "    if done and i != (strategic_horizon // tactical_horizon - 1):\n",
    "        print(\"The episode is done before the end of the strategic horizon!\")\n",
    "        break\n",
    "agent.display_grid()\n",
    "print(f\"\\n* Cumulative reward: {cumulative_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
